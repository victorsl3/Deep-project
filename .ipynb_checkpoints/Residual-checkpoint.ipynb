{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, minmax_scale, scale\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path= \"/home/21953404Victor/Deep/drive-download-20231121T165626Z-001/HotelReservationsPreparedCleanAttributes.csv\"\n",
    "label_path = \"/home/21953404Victor/Deep/drive-download-20231121T165626Z-001/HotelReservationsOutput.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features  = pd.read_csv(data_path)\n",
    "labels = pd.read_csv(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Divide el conjunto de datos\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features.values, labels.values, test_size=0.1, random_state=42)\n",
    "features_train, features_val, labels_train, labels_val = train_test_split(features_train, labels_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Convierte los arrays a tensores de PyTorch\n",
    "features_train = torch.tensor(features_train).float()\n",
    "labels_train = torch.tensor(labels_train).float()\n",
    "features_val = torch.tensor(features_val).float()\n",
    "labels_val = torch.tensor(labels_val).float()\n",
    "features_test = torch.tensor(features_test).float()\n",
    "labels_test = torch.tensor(labels_test).float()\n",
    "\n",
    "# Crea conjuntos de datos de PyTorch\n",
    "train_dataset = TensorDataset(features_train, labels_train)\n",
    "val_dataset = TensorDataset(features_val, labels_val)\n",
    "test_dataset = TensorDataset(features_test, labels_test)\n",
    "\n",
    "# Crea DataLoaders de PyTorch\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 18:51:58.065541: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 18:51:58.197515: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-29 18:51:58.781957: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hadoop/lib/native:/opt/hadoop/lib/native:\n",
      "2023-11-29 18:51:58.782015: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hadoop/lib/native:/opt/hadoop/lib/native:\n",
      "2023-11-29 18:51:58.782019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible: True\n",
      "Listado de dispositivos GPU disponibles:\n",
      "GPU 0: NVIDIA GeForce RTX 3080 Ti\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "# Verificar si CUDA está disponible\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA disponible: {cuda_available}\")\n",
    "\n",
    "# Enumerar dispositivos de GPU disponibles y mostrar sus nombres si CUDA está disponible\n",
    "if cuda_available:\n",
    "    print(\"Listado de dispositivos GPU disponibles:\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No se detectó una GPU. Asegúrate de que el acelerador de hardware esté configurado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "class PyTorchModel(nn.Module):\n",
    "    def __init__(self, trial, input_shape):\n",
    "        super(PyTorchModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.l2_regs = []\n",
    "        current_shape = input_shape\n",
    "\n",
    "        # Diccionario para rastrear capas elegibles para conexiones residuales, organizadas por tamaño\n",
    "        potential_residuals = {size: [] for size in [16, 32, 64, 128, 256, 512, 1024, 2048]}\n",
    "        self.residual_connections = {}\n",
    "\n",
    "        n_layers = trial.suggest_int('n_layers', 1, 100)\n",
    "        \n",
    "        # Optimizar el umbral para conexiones residuales\n",
    "        residual_threshold_factor = trial.suggest_float('residual_threshold_factor', 0.5, 1.0)\n",
    "        residual_treshold = int(n_layers * residual_threshold_factor)\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            num_units = trial.suggest_categorical(f'n_units_l{i}', [16, 32, 64, 128, 256, 512, 1024, 2048])\n",
    "            activation = trial.suggest_categorical(f'activation_l{i}', ['ReLU', 'Tanh', 'ELU', 'SELU', 'LeakyReLU'])\n",
    "            dropout_rate = trial.suggest_float(f'dropout_l{i}', 0.0, 0.5)\n",
    "            use_batch_norm = trial.suggest_categorical(f'batch_norm_l{i}', [True, False])\n",
    "            l2_reg = trial.suggest_float(f'l2_reg_l{i}', 1e-5, 1e-1, log=True)\n",
    "\n",
    "            # Crear y añadir la capa lineal\n",
    "            layer = nn.Linear(current_shape, num_units)\n",
    "            self.layers.append(layer)\n",
    "            self.l2_regs.append(l2_reg)\n",
    "            \n",
    "            if num_units in potential_residuals and i >= residual_treshold:\n",
    "                potential_residuals[num_units].append(i)\n",
    "\n",
    "            # Añadir Batch Normalization y Dropout\n",
    "            if use_batch_norm:\n",
    "                self.layers.append(nn.BatchNorm1d(num_units))\n",
    "            self.layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "            # Añadir la activación\n",
    "            if activation == 'LeakyReLU':\n",
    "                negative_slope = trial.suggest_float(f'leakyrelu_alpha_l{i}', 0.01, 0.3)\n",
    "                self.layers.append(nn.LeakyReLU(negative_slope=negative_slope))\n",
    "            else:\n",
    "                self.layers.append(getattr(nn, activation)())\n",
    "\n",
    "            current_shape = num_units\n",
    "\n",
    "            # Configurar conexiones residuales\n",
    "            if i >= residual_treshold and num_units in potential_residuals:\n",
    "                res_index = trial.suggest_int(f'res_connection_index_l{i}', 0, len(potential_residuals[num_units]) - 1)\n",
    "                self.residual_connections[i] = potential_residuals[num_units][res_index]\n",
    "\n",
    "        # Capa de salida\n",
    "        self.output = nn.Linear(current_shape, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer_outputs = {}\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            layer_outputs[i] = x.clone()\n",
    "            if i in self.residual_connections:\n",
    "                res_layer = self.residual_connections[i]\n",
    "                if layer_outputs[res_layer].size(1) == x.size(1):\n",
    "                    x = x + layer_outputs[res_layer]\n",
    "        return torch.sigmoid(self.output(x))\n",
    "\n",
    "    def get_l2_loss(self):\n",
    "        l2_loss = 0.0\n",
    "        for layer, l2_reg in zip(self.layers, self.l2_regs):\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                l2_loss += l2_reg * layer.weight.norm(2)\n",
    "        return l2_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada capa tiene una lista de posibles capas anteriores con las que puede tener una conexión residual. Para redes con más de residual_treshold capas, el optimizador decide si se realiza una conexión residual y con qué capa anterior, limitando el número máximo de conexiones residuales a 10. La función forward se ha modificado para manejar estas conexiones residuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD, RMSprop\n",
    "\n",
    "def build_model(params, input_shape, is_trial=True):\n",
    "    # Crear una instancia del modelo con la arquitectura definida\n",
    "    model = PyTorchModel(params, input_shape)\n",
    "\n",
    "    if is_trial:\n",
    "        # Configuración durante la optimización con Optuna\n",
    "        optimizer_name = params.suggest_categorical('optimizer', ['Adam', 'SGD', 'RMSprop'])\n",
    "        lr = params.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "        if optimizer_name == 'Adam':\n",
    "            beta1 = params.suggest_float('adam_beta1', 0.85, 0.99)\n",
    "            beta2 = params.suggest_float('adam_beta2', 0.9, 0.999)\n",
    "            optimizer = Adam(model.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "        elif optimizer_name == 'SGD':\n",
    "            momentum = params.suggest_float('sgd_momentum', 0.1, 0.9)\n",
    "            optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "        elif optimizer_name == 'RMSprop':\n",
    "            alpha = params.suggest_float('rmsprop_alpha', 0.85, 0.99)\n",
    "            optimizer = RMSprop(model.parameters(), lr=lr, alpha=alpha)\n",
    "    else:\n",
    "        # Configuración con parámetros fijos\n",
    "        optimizer_name = params['optimizer']\n",
    "        if optimizer_name == 'Adam':\n",
    "            optimizer = Adam(model.parameters(), lr=params['lr'], betas=(params['adam_beta1'], params['adam_beta2']))\n",
    "        elif optimizer_name == 'SGD':\n",
    "            optimizer = SGD(model.parameters(), lr=params['lr'], momentum=params.get('sgd_momentum', 0.9))\n",
    "        elif optimizer_name == 'RMSprop':\n",
    "            optimizer = RMSprop(model.parameters(), lr=params['lr'], alpha=params.get('rmsprop_alpha', 0.99))\n",
    "\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    predicted = outputs.round()  # Redondear para obtener las predicciones binarias\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct / labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, file_name_base):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Pérdida\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Pérdida durante el entrenamiento')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.legend()\n",
    "\n",
    "    # Precisión\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Precisión durante el entrenamiento')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f\"{file_name_base}_plot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor accuracy global: 0.678407350689127\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "best_accuracy_file = \"global_best_accuracy_residual.json\"\n",
    "\n",
    "# Intenta cargar la mejor precisión global desde un archivo\n",
    "try:\n",
    "    with open(best_accuracy_file, \"r\") as file:\n",
    "        global_best_accuracy = json.load(file)\n",
    "except (FileNotFoundError, json.JSONDecodeError, TypeError, ValueError):\n",
    "    global_best_accuracy = 0.0\n",
    "    \n",
    "best_model_path = \"best_model_residual.pt\"\n",
    "plot_file_name_base = \"best_model_residual\"\n",
    "\n",
    "print(f\"Mejor accuracy global: {global_best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def objective(trial):\n",
    "    global global_best_accuracy, best_model_path, plot_file_name_base\n",
    "    # Verificar y configurar el uso de la GPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Usando {'GPU' if device.type == 'cuda' else 'CPU'} para el Trial {trial.number}\")\n",
    "\n",
    "    model, optimizer = build_model(trial, input_shape)  # Asegúrate de que 'input_shape' esté definido\n",
    "    model.to(device)\n",
    "\n",
    "    # Parametrización del número de épocas y tamaño del batch\n",
    "    epochs = trial.suggest_int('epochs', 10, 2000)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128, 256, 512, 1024, 2048])\n",
    "\n",
    "    # Criterio de pérdida y DataLoader\n",
    "    criterion = torch.nn.BCELoss()  # Ajustar según tu problema\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Configuración de Early Stopping y Learning Rate Scheduler\n",
    "    early_stopping_patience = trial.suggest_int('early_stopping_patience', 3, 20)\n",
    "    factor = trial.suggest_float(\"lr_reduce_factor\", 0.1, 0.9)\n",
    "    lr_patience = trial.suggest_int(\"lr_reduce_patience\", 5, 50)\n",
    "    min_lr = trial.suggest_float(\"min_lr\", 1e-6, 1e-4, log=True)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=factor, patience=lr_patience, min_lr=min_lr, verbose=True)\n",
    "\n",
    "    # Entrenamiento del modelo\n",
    "    print(f\"Entrenando Trial {trial.number}...\")\n",
    "    best_accuracy = 0.0  # Inicializacion de la mejor precisión\n",
    "    epochs_no_improve = 0\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            train_correct += calculate_accuracy(outputs, labels) * inputs.size(0)\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "        train_loss /= train_total\n",
    "        train_accuracy = train_correct / train_total\n",
    "\n",
    "        # Almacenar las métricas de entrenamiento\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Evaluación y Early Stopping\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, labels).item() * inputs.size(0)\n",
    "                val_correct += calculate_accuracy(outputs, labels) * inputs.size(0)\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        # Almacenar las métricas de validación\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        lr_scheduler.step(val_loss)\n",
    "\n",
    "        # Comprobar si este modelo es el mejor hasta ahora\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            if best_accuracy > global_best_accuracy:\n",
    "                global_best_accuracy = best_accuracy\n",
    "                # Guardar el nuevo valor de global_best_accuracy\n",
    "                with open(best_accuracy_file, \"w\") as file:\n",
    "                    json.dump(global_best_accuracy, file)\n",
    "                torch.save(model.state_dict(), best_model_path)  # Sobreescribir el mejor modelo\n",
    "                plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, plot_file_name_base)  # Sobreescribir el gráfico\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve == early_stopping_patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "            \n",
    "    print(f\"Trial {trial.number} completado. Mejor precisión en validación: {best_accuracy}\")\n",
    "\n",
    "    # Limpiar la memoria después de cada trial\n",
    "    del model, optimizer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # Devolver la pérdida en lugar de la precisión\n",
    "    return best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = features_train.shape[1]  # Número de variables explicativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/21953404Victor/SDC3/tutorial-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m[I 2023-11-29 18:51:59,544]\u001b[0m Using an existing study with name 'residual_accuracy_gpu_study3' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El estudio contiene 4 ensayos.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "storage = \"sqlite:///example.db\"  # Ruta de la base de datos SQLite\n",
    "study_name = \"residual_accuracy_gpu_study3\"  # Nuevo nombre del estudio\n",
    "\n",
    "# Crear un nuevo estudio\n",
    "study = optuna.create_study(study_name=study_name, direction='maximize', storage=storage, load_if_exists=True)\n",
    "\n",
    "# Número de ensayos en el estudio\n",
    "num_trials = len(study.trials)\n",
    "print(f\"El estudio contiene {num_trials} ensayos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando GPU para el Trial 4\n",
      "Entrenando Trial 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/1254:  12%|███████████████████████                                                                                                                                                                             | 27/230 [00:00<00:06, 30.10it/s]"
     ]
    }
   ],
   "source": [
    "trials_restantes=50000-num_trials\n",
    "study.optimize(objective, n_trials=trials_restantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Número de pruebas finalizadas:', len(study.trials))\n",
    "print('Mejor prueba:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "# Crear el modelo, el optimizador y el scheduler usando la función build_model\n",
    "model, optimizer = build_model(best_params, input_shape, is_trial=False)\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Criterio de pérdida\n",
    "criterion = nn.BCELoss()  # Ajusta según tu caso\n",
    "\n",
    "# Función para calcular la precisión\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    predicted = outputs.round()  # Redondear para obtener las predicciones binarias\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct / labels.size(0)\n",
    "\n",
    "# Variables para almacenar métricas y manejar el early stopping\n",
    "best_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "early_stopping_patience = best_params['early_stopping_patience']\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucle de entrenamiento\n",
    "epochs = best_params['epochs']\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", leave=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += calculate_accuracy(outputs, labels) * inputs.size(0)\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "    train_loss /= train_total\n",
    "    train_accuracy = train_correct / train_total\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Evaluación y Early Stopping\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item() * inputs.size(0)\n",
    "            val_correct += calculate_accuracy(outputs, labels) * inputs.size(0)\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_loss /= val_total\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    lr_scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # Descomentar si deseas aplicar early stopping\n",
    "    # if epochs_no_improve == early_stopping_patience:\n",
    "    #     print(\"Early stopping\")\n",
    "    #     break\n",
    "\n",
    "print(f\"Entrenamiento completado. Mejor precisión en validación: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la pérdida y la precisión\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Pérdida\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Pérdida durante el entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "# Precisión\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Precisión durante el entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "model.evaluate(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# Asegurarse de que el modelo esté en modo de evaluación y moverlo al dispositivo adecuado\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Realizar las predicciones\n",
    "with torch.no_grad():\n",
    "    inputs = features_test.to(device)\n",
    "    outputs = model(inputs)\n",
    "    predictions = outputs.round().cpu().numpy()  # Redondear las predicciones y moverlas al CPU\n",
    "\n",
    "# Calcular y visualizar la matriz de confusión\n",
    "conf_matrix = confusion_matrix(labels_test.numpy(), predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicciones')\n",
    "plt.ylabel('Valores Reales')\n",
    "plt.show()\n",
    "\n",
    "# Calcular y mostrar otras métricas\n",
    "accuracy = accuracy_score(labels_test.numpy(), predictions)\n",
    "recall = recall_score(labels_test.numpy(), predictions)\n",
    "precision = precision_score(labels_test.numpy(), predictions)\n",
    "f1 = f1_score(labels_test.numpy(), predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial-env",
   "language": "python",
   "name": "tutorial-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
